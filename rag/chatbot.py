"""
RAG ì±—ë´‡ êµ¬í˜„
í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥(í•˜ì´ë¸Œë¦¬ë“œ, í’ˆì§ˆ í•„í„°ë§, ìš°ì„ ìˆœìœ„)ì„ í™œìš©í•œ ì±—ë´‡
"""

import json
from typing import List, Dict, Any, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
import sys
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from rag.retriever import EnhancedRetriever


class RAGChatbot:
    """í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œìš©í•˜ëŠ” RAG ì±—ë´‡"""
    
    def __init__(self, retriever: Optional[EnhancedRetriever] = None):
        """
        Args:
            retriever: EnhancedRetriever ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìë™ ìƒì„±)
        """
        self.retriever = retriever or EnhancedRetriever()
        self.conversation_history = []
        
    def search_context(self, query: str, search_method: str = "hybrid", **kwargs) -> List[Dict[str, Any]]:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            search_method: ê²€ìƒ‰ ë°©ë²•
                - "hybrid": í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ê¸°ë³¸)
                - "semantic": ì˜ë¯¸ì  ê²€ìƒ‰ë§Œ
                - "keyword": í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ
                - "quality": í’ˆì§ˆ í•„í„°ë§ ê²€ìƒ‰
                - "priority": ìš°ì„ ìˆœìœ„ ê²€ìƒ‰
                - "enhanced": í–¥ìƒëœ ê²€ìƒ‰ (ì—‘ì…€ ìš°ì„  + í•˜ì´ë¸Œë¦¬ë“œ)
            **kwargs: ê²€ìƒ‰ íŒŒë¼ë¯¸í„° (n_results, min_quality_score ë“±)
        
        Returns:
            ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        n_results = kwargs.get('n_results', 5)
        
        if search_method == "enhanced":
            return self._enhanced_search(query, n_results)
        elif search_method == "hybrid":
            return self.retriever.hybrid_search(query, n_results)
        elif search_method == "semantic":
            return self.retriever.semantic_search(query, n_results)
        elif search_method == "keyword":
            return self.retriever.keyword_search(query, n_results)
        elif search_method == "quality":
            min_quality = kwargs.get('min_quality_score', 0.5)
            return self.retriever.quality_filtered_search(query, n_results, min_quality)
        elif search_method == "priority":
            return self.retriever.search_by_priority(query, n_results)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²€ìƒ‰ ë°©ë²•: {search_method}")
    
    def _enhanced_search(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """í–¥ìƒëœ ê²€ìƒ‰: ì—‘ì…€ ë°ì´í„° ìš°ì„  + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        
        # 1. í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ì—‘ì…€ ë°ì´í„° ìš°ì„  ì°¾ê¸°
        keyword_results = self.retriever.keyword_search(query, n_results * 2)
        
        # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ì „ì²´ ê²€ìƒ‰
        hybrid_results = self.retriever.hybrid_search(query, n_results * 2)
        
        # 3. ê²°ê³¼ í†µí•© ë° ì •ë ¬
        combined_results = {}
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ (ì—‘ì…€ ìš°ì„ ) - ê°€ì¤‘ì¹˜ ë†’ê²Œ
        for result in keyword_results:
            chunk_id = result['chunk_id']
            if chunk_id not in combined_results:
                combined_results[chunk_id] = {
                    'chunk_id': chunk_id,
                    'content': result['content'],
                    'metadata': result['metadata'],
                    'score': result.get('score', 0) * 2.0,  # ì—‘ì…€ ë°ì´í„° ê°€ì¤‘ì¹˜ ëŒ€í­ ì¦ê°€
                    'source': 'keyword'
                }
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (í‚¤ì›Œë“œ ê²°ê³¼ê°€ ì—†ì„ ë•Œë§Œ)
        for result in hybrid_results:
            chunk_id = result['chunk_id']
            if chunk_id not in combined_results:  # í‚¤ì›Œë“œ ê²°ê³¼ê°€ ì—†ì„ ë•Œë§Œ ì¶”ê°€
                combined_results[chunk_id] = {
                    'chunk_id': chunk_id,
                    'content': result['content'],
                    'metadata': result['metadata'],
                    'score': result.get('final_score', result.get('score', 0)),
                    'source': 'hybrid'
                }
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_results = sorted(
            combined_results.values(),
            key=lambda x: x['score'],
            reverse=True
        )
        
        return sorted_results[:n_results]
    
    def format_context_for_llm(self, contexts: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ LLM ì…ë ¥ìš©ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        if not contexts:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_contexts = []
        for i, context in enumerate(contexts, 1):
            chunk_id = context.get('chunk_id', 'unknown')
            content = context.get('content', '')
            score = context.get('final_score', context.get('score', 0))
            metadata = context.get('metadata', {})
            
            # ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
            document_id = chunk_id.split('_')[0] if '_' in chunk_id else chunk_id
            location = metadata.get('location', 'unknown')
            title = metadata.get('title', '')
            
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(content) > 400:
                content = content[:400] + "..."
            
            # êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ í¬ë§·
            context_info = f"[{i}] ğŸ“„ ë¬¸ì„œ: {document_id}"
            if location != 'unknown':
                context_info += f" | ğŸ“ ìœ„ì¹˜: {location}"
            if title:
                context_info += f" | ğŸ“ ì œëª©: {title}"
            context_info += f" | â­ ì ìˆ˜: {score:.3f}\n"
            context_info += f"ğŸ’¬ ë‚´ìš©: {content}"
            
            formatted_contexts.append(context_info)
        
        return "\n\n".join(formatted_contexts)
    
    def generate_response(self, query: str, contexts: List[Dict[str, Any]]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤ (LLM ì‹œë®¬ë ˆì´ì…˜)"""
        if not contexts:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        excel_contents = []
        pdf_contents = []
        all_contents = []
        
        for ctx in contexts[:10]:  # ìƒìœ„ 10ê°œ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            content = ctx.get('content', '')
            chunk_id = ctx.get('chunk_id', '')
            metadata = ctx.get('metadata', {})
            
            if content and len(content.strip()) > 10:  # ì˜ë¯¸ìˆëŠ” ë‚´ìš©ë§Œ
                all_contents.append({
                    'content': content.strip(),
                    'chunk_id': chunk_id,
                    'metadata': metadata,
                    'score': ctx.get('score', 0)
                })
                
                # ë¬¸ì„œ íƒ€ì…ë³„ ë¶„ë¥˜ (chunk_id ê¸°ë°˜)
                if 'excel' in chunk_id.lower():
                    excel_contents.append({
                        'content': content.strip(),
                        'chunk_id': chunk_id,
                        'metadata': metadata,
                        'score': ctx.get('score', 0)
                    })
                elif 'pdf' in chunk_id.lower() or 'smart_yard' in chunk_id.lower():
                    pdf_contents.append({
                        'content': content.strip(),
                        'chunk_id': chunk_id,
                        'metadata': metadata,
                        'score': ctx.get('score', 0)
                    })
        
        if not all_contents:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ì§€ë§Œ êµ¬ì²´ì ì¸ ë‚´ìš©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        query_lower = query.lower()
        
        # ê³µì • ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬
        if any(keyword in query_lower for keyword in ["ê³µì •", "ì§€ì—°", "ì´ìŠˆ", "ì£¼ì°¨", "ìœ„í—˜", "ë°¸ë¸Œì¬", "í˜‘ë ¥ì‚¬", "ì…ê³ ", "ì‚¬ì™¸ë¸”ë¡"]):
            response = "ê³µì • ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            
            if excel_contents:
                # ì—‘ì…€ ë°ì´í„° ê¸°ë°˜ ë‹µë³€
                response += "ğŸ“Š ê³µì • ì´ìŠˆ í˜„í™©:\n"
                
                # ì£¼ì°¨ë³„ ì´ìŠˆ ë¶„ì„
                if "ì£¼ì°¨" in query_lower:
                    response += "ì£¼ì°¨ë³„ ì´ìŠˆ í˜„í™©:\n"
                    for item in excel_contents[:3]:
                        content = item['content']
                        if "ì£¼ì°¨:" in content:
                            response += f"â€¢ {content[:300]}...\n"
                    response += "\n"
                
                # ì§€ì—° ê´€ë ¨ ë¶„ì„
                if "ì§€ì—°" in query_lower:
                    response += "ê³µì • ì§€ì—° ê´€ë ¨ ì´ìŠˆ:\n"
                    for item in excel_contents:
                        content = item['content']
                        if "ì§€ì—°" in content:
                            response += f"â€¢ {content[:300]}...\n"
                    response += "\n"
                
                # ì´ìŠˆ ë¶„ì„
                if "ì´ìŠˆ" in query_lower:
                    response += "ì£¼ìš” ì´ìŠˆ í˜„í™©:\n"
                    for item in excel_contents[:3]:
                        content = item['content']
                        if "ì´ìŠˆ:" in content:
                            response += f"â€¢ {content[:300]}...\n"
                    response += "\n"
                
                # ë°¸ë¸Œì¬ ê´€ë ¨
                if "ë°¸ë¸Œì¬" in query_lower:
                    response += "ë°¸ë¸Œì¬ ê´€ë ¨ ì´ìŠˆ:\n"
                    for item in excel_contents:
                        content = item['content']
                        if "ë°¸ë¸Œì¬" in content:
                            response += f"â€¢ {content[:300]}...\n"
                    response += "\n"
                
                # í˜‘ë ¥ì‚¬ ê´€ë ¨
                if "í˜‘ë ¥ì‚¬" in query_lower:
                    response += "í˜‘ë ¥ì‚¬ ê´€ë ¨ ì´ìŠˆ:\n"
                    for item in excel_contents:
                        content = item['content']
                        if "í˜‘ë ¥ì‚¬" in content:
                            response += f"â€¢ {content[:300]}...\n"
                    response += "\n"
                
                # ëŒ€ì‘ë°©ì•ˆ
                response += "ëŒ€ì‘ë°©ì•ˆ:\n"
                for item in excel_contents:
                    content = item['content']
                    if "ëŒ€ì‘ë°©ì•ˆ:" in content:
                        response += f"â€¢ {content[:300]}...\n"
                        break
                
            else:
                # PDF ë°ì´í„° ê¸°ë°˜ ë‹µë³€
                response += "ê´€ë ¨ ì •ë³´:\n"
                for item in all_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            sources = set()
            for item in all_contents[:3]:
                chunk_id = item['chunk_id']
                doc_name = chunk_id.split('_')[0] if '_' in chunk_id else chunk_id
                sources.add(doc_name)
            
            response += f"\nğŸ“ ì¶œì²˜: {', '.join(sources)}\n\n"
        
        # ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ê´€ë ¨ ì§ˆë¬¸
        elif "ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ" in query_lower or "ìŠ¤ë§ˆíŠ¸ì•¼ë“œ" in query_lower:
            response = "ìŠ¤ë§ˆíŠ¸ ì•¼ë“œì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            
            if pdf_contents:
                response += "ğŸ“‹ ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ì •ë³´:\n"
                for item in pdf_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            else:
                response += "ê´€ë ¨ ì •ë³´:\n"
                for item in all_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            sources = set()
            for item in all_contents[:3]:
                chunk_id = item['chunk_id']
                doc_name = chunk_id.split('_')[0] if '_' in chunk_id else chunk_id
                sources.add(doc_name)
            
            response += f"\nğŸ“ ì¶œì²˜: {', '.join(sources)}\n\n"
        
        # ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸
        elif any(keyword in query_lower for keyword in ["ê¸°ìˆ ", "ai", "ì¸ê³µì§€ëŠ¥", "ìë™í™”", "iot"]):
            response = "ê¸°ìˆ  ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            
            if pdf_contents:
                response += "ğŸ”§ ê¸°ìˆ  ì •ë³´:\n"
                for item in pdf_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            else:
                response += "ê´€ë ¨ ì •ë³´:\n"
                for item in all_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            sources = set()
            for item in all_contents[:3]:
                chunk_id = item['chunk_id']
                doc_name = chunk_id.split('_')[0] if '_' in chunk_id else chunk_id
                sources.add(doc_name)
            
            response += f"\nğŸ“ ì¶œì²˜: {', '.join(sources)}\n\n"
        
        # ì¼ë°˜ì ì¸ ì§ˆë¬¸
        else:
            response = "ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
            
            # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì»¨í…ì¸  ì„ íƒ
            if excel_contents:
                response += "ğŸ“Š ë°ì´í„° ê¸°ë°˜ ì •ë³´:\n"
                for item in excel_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            elif pdf_contents:
                response += "ğŸ“‹ ë¬¸ì„œ ê¸°ë°˜ ì •ë³´:\n"
                for item in pdf_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            else:
                response += "ê´€ë ¨ ì •ë³´:\n"
                for item in all_contents[:3]:
                    response += f"â€¢ {item['content'][:300]}...\n"
            
            # ì¶œì²˜ ì •ë³´ ì¶”ê°€
            sources = set()
            for item in all_contents[:3]:
                chunk_id = item['chunk_id']
                doc_name = chunk_id.split('_')[0] if '_' in chunk_id else chunk_id
                sources.add(doc_name)
            
            response += f"\nğŸ“ ì¶œì²˜: {', '.join(sources)}\n\n"
        
        response += "ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."
        return response
    
    def chat(self, query: str, search_method: str = "enhanced", **kwargs) -> Dict[str, Any]:
        """
        ì±—ë´‡ê³¼ ëŒ€í™”í•©ë‹ˆë‹¤.
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            search_method: ê²€ìƒ‰ ë°©ë²•
            **kwargs: ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        
        Returns:
            ì‘ë‹µ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        # 1. ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        contexts = self.search_context(query, search_method, **kwargs)
        
        # 2. ì‘ë‹µ ìƒì„±
        response = self.generate_response(query, contexts)
        
        # 3. ëŒ€í™” ê¸°ë¡ ì €ì¥
        conversation_entry = {
            "query": query,
            "search_method": search_method,
            "contexts_found": len(contexts),
            "response": response,
            "contexts": contexts
        }
        self.conversation_history.append(conversation_entry)
        
        return {
            "query": query,
            "response": response,
            "contexts_found": len(contexts),
            "search_method": search_method,
            "contexts": contexts
        }
    
    def compare_search_methods(self, query: str) -> Dict[str, Any]:
        """ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²•ì„ ë¹„êµí•©ë‹ˆë‹¤."""
        methods = ["hybrid", "semantic", "keyword", "quality", "priority"]
        results = {}
        
        for method in methods:
            try:
                contexts = self.search_context(query, method, n_results=3)
                results[method] = {
                    "contexts_found": len(contexts),
                    "avg_score": sum(ctx.get('final_score', ctx.get('score', 0)) for ctx in contexts) / len(contexts) if contexts else 0,
                    "top_context": contexts[0] if contexts else None
                }
            except Exception as e:
                results[method] = {"error": str(e)}
        
        return results
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.conversation_history
    
    def clear_history(self):
        """ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.conversation_history = []


def test_rag_chatbot():
    """RAG ì±—ë´‡ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¤– RAG ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ì±—ë´‡ ì´ˆê¸°í™”
    chatbot = RAGChatbot()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "ìŠ¤ë§ˆíŠ¸ ì•¼ë“œë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ìë™í™” ê¸°ìˆ ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "AI ê¸°ìˆ ì´ ì–´ë–»ê²Œ í™œìš©ë˜ë‚˜ìš”?",
        "ì¡°ì„ ì†Œì˜ ìƒì‚°ì„± í–¥ìƒ ë°©ë²•ì€?",
        "ìŠ¤ë§ˆíŠ¸ ì•¼ë“œì˜ ì£¼ìš” ê¸°ìˆ  ìš”ì†ŒëŠ”?"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ” ì§ˆë¬¸ {i}: {query}")
        print("-" * 40)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ì‘ë‹µ
        result = chatbot.chat(query, search_method="hybrid", n_results=3)
        
        print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {result['contexts_found']}ê°œ ì»¨í…ìŠ¤íŠ¸")
        print(f"ğŸ¤– ì‘ë‹µ: {result['response'][:200]}...")
        
        # ìƒìœ„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        if result['contexts']:
            top_context = result['contexts'][0]
            print(f"ğŸ† ìµœê³  ì ìˆ˜ ì»¨í…ìŠ¤íŠ¸: {top_context.get('chunk_id', 'unknown')} (ì ìˆ˜: {top_context.get('final_score', 0):.3f})")
    
    # ê²€ìƒ‰ ë°©ë²• ë¹„êµ
    print(f"\nğŸ” ê²€ìƒ‰ ë°©ë²• ë¹„êµ: 'ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ìë™í™”'")
    print("=" * 50)
    
    comparison = chatbot.compare_search_methods("ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ìë™í™”")
    for method, result in comparison.items():
        if "error" in result:
            print(f"  {method.upper()}: âŒ {result['error']}")
        else:
            print(f"  {method.upper()}: {result['contexts_found']}ê°œ ì»¨í…ìŠ¤íŠ¸, í‰ê·  ì ìˆ˜ {result['avg_score']:.3f}")
    
    # ëŒ€í™” ê¸°ë¡ ìš”ì•½
    history = chatbot.get_conversation_history()
    print(f"\nğŸ“‹ ëŒ€í™” ê¸°ë¡: {len(history)}ê°œ ì§ˆë¬¸")
    
    return chatbot


if __name__ == "__main__":
    chatbot = test_rag_chatbot()
