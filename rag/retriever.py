"""
RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ë° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ëª¨ë“ˆ
í’ˆì§ˆ ì ìˆ˜, í‚¤ì›Œë“œ ë§¤ì¹­, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë“±ì„ ì§€ì›
"""

import json
from typing import List, Dict, Any, Optional
from pathlib import Path
import chromadb
from chromadb.config import Settings
import numpy as np
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction

embedding_function = SentenceTransformerEmbeddingFunction(
    model_name="all-MiniLM-L6-v2",
    device="cpu",
    use_onnx=False  # âœ… ì´ê±° ê¼­ ì¶”ê°€!
)


class EnhancedRetriever:
    """í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” Retriever í´ëž˜ìŠ¤"""
    
    def __init__(self, db_path: str = "data/db/chroma"):
        """
        Args:
            db_path: ChromaDB ì €ìž¥ ê²½ë¡œ
        """
        self.db_path = Path(db_path)
        self.db_path.mkdir(parents=True, exist_ok=True)
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = chromadb.PersistentClient(
            path=str(self.db_path),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # ì»¬ë ‰ì…˜ ì´ë¦„
        self.collection_name = "documents"
        
        # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        try:
            self.collection = self.client.get_collection(self.collection_name)
        except:
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "Document chunks for RAG system"}
            )
    
    def add_chunks(self, chunks: List[Dict[str, Any]]):
        """ì²­í¬ë“¤ì„ ë²¡í„° DBì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if not chunks:
            return
        
        # ì²­í¬ ë°ì´í„° ì¤€ë¹„
        ids = []
        documents = []
        metadatas = []
        
        for chunk in chunks:
            chunk_id = chunk.get("chunk_id", "")
            content = chunk.get("content", "")
            metadata = chunk.get("metadata", {})
            
            if chunk_id and content:
                # ChromaDB í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ metadata ë³€í™˜
                chroma_metadata = self._convert_metadata_for_chroma(metadata)
                
                ids.append(chunk_id)
                documents.append(content)
                metadatas.append(chroma_metadata)
        
        # ë²¡í„° DBì— ì¶”ê°€ (ChromaDBê°€ ìžë™ìœ¼ë¡œ ìž„ë² ë”© ìƒì„±)
        if ids:
            self.collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas
            )
            print(f"[âœ“] {len(ids)}ê°œ ì²­í¬ë¥¼ ë²¡í„° DBì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
    
    def _convert_metadata_for_chroma(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ChromaDB í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ metadata ë³€í™˜"""
        import json
        
        chroma_metadata = {}
        
        for key, value in metadata.items():
            if isinstance(value, list):
                # ë¦¬ìŠ¤íŠ¸ëŠ” JSON ë¬¸ìžì—´ë¡œ ë³€í™˜ (ë” ì•ˆì „í•¨)
                chroma_metadata[key] = json.dumps(value, ensure_ascii=False)
            elif isinstance(value, dict):
                # ë”•ì…”ë„ˆë¦¬ë„ JSON ë¬¸ìžì—´ë¡œ ë³€í™˜
                chroma_metadata[key] = json.dumps(value, ensure_ascii=False)
            elif isinstance(value, (str, int, float, bool)) or value is None:
                # ChromaDBê°€ ì§€ì›í•˜ëŠ” íƒ€ìž…ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                chroma_metadata[key] = value
            else:
                # ê¸°íƒ€ íƒ€ìž…ì€ ë¬¸ìžì—´ë¡œ ë³€í™˜
                chroma_metadata[key] = str(value)
        
        return chroma_metadata
    
    def keyword_search(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„°ì˜ keywords í•„ë“œ í™œìš©)"""
        # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        import re
        query_keywords = re.findall(r'[ê°€-íž£a-zA-Z0-9]+', query)
        query_keywords = [kw for kw in query_keywords if len(kw) >= 2]
        
        if not query_keywords:
            return []
        
        # ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        all_docs = self.collection.get()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        scored_results = []
        if all_docs['metadatas']:
            for i, metadata in enumerate(all_docs['metadatas']):
                if not metadata:
                    continue
                    
                # keywords í•„ë“œë¥¼ ë¬¸ìžì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
                keywords_str = metadata.get('keywords', '')
                if isinstance(keywords_str, str):
                    try:
                        # JSON ë¬¸ìžì—´ì¸ ê²½ìš° íŒŒì‹±
                        if keywords_str.startswith('[') and keywords_str.endswith(']'):
                            import json
                            chunk_keywords = json.loads(keywords_str)
                        else:
                            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìžì—´ì¸ ê²½ìš°
                            chunk_keywords = [kw.strip() for kw in keywords_str.split(',') if kw.strip()]
                    except:
                        # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì‰¼í‘œë¡œ ë¶„ë¦¬
                        chunk_keywords = [kw.strip() for kw in keywords_str.split(',') if kw.strip()]
                else:
                    chunk_keywords = []
                
                if not chunk_keywords:
                    continue
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                matches = set(query_keywords) & set(chunk_keywords)
                if matches:
                    score = len(matches) / len(query_keywords)
                    quality_score = metadata.get('quality_score', 0)
                    if not isinstance(quality_score, (int, float)):
                        quality_score = 0
                    
                    # ìµœì¢… ì ìˆ˜ = í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ * í’ˆì§ˆ ì ìˆ˜
                    final_score = score * quality_score
                    
                    scored_results.append({
                        'chunk_id': all_docs['ids'][i],
                        'content': all_docs['documents'][i],
                        'metadata': metadata,
                        'score': final_score,
                        'keyword_matches': list(matches)
                    })
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_results.sort(key=lambda x: x['score'], reverse=True)
        
        return scored_results[:n_results]
    
    def semantic_search(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """ì˜ë¯¸ì  ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„)"""
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results
            )
            
            # ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            formatted_results = []
            if results['ids'] and results['ids'][0]:  # ê²°ê³¼ê°€ ìžˆëŠ” ê²½ìš°
                for i in range(len(results['ids'][0])):
                    formatted_results.append({
                        'chunk_id': results['ids'][0][i],
                        'content': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {},
                        'distance': results['distances'][0][i] if 'distances' in results and results['distances'] and results['distances'][0] else None,
                        'score': 1 - (results['distances'][0][i] if 'distances' in results and results['distances'] and results['distances'][0] else 0)
                    })
            
            return formatted_results
        except Exception as e:
            print(f"[âš ï¸] ì˜ë¯¸ì  ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def hybrid_search(self, query: str, n_results: int = 5, 
                     semantic_weight: float = 0.7, keyword_weight: float = 0.3) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ì˜ë¯¸ì  + í‚¤ì›Œë“œ)"""
        # ê°ê°ì˜ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        semantic_results = self.semantic_search(query, n_results * 2)
        keyword_results = self.keyword_search(query, n_results * 2)
        
        # ê²°ê³¼ í†µí•©
        combined_results = {}
        
        # ì˜ë¯¸ì  ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        for result in semantic_results:
            chunk_id = result['chunk_id']
            combined_results[chunk_id] = {
                'chunk_id': chunk_id,
                'content': result['content'],
                'metadata': result['metadata'],
                'semantic_score': result['score'],
                'keyword_score': 0,
                'final_score': result['score'] * semantic_weight
            }
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€/ì—…ë°ì´íŠ¸
        for result in keyword_results:
            chunk_id = result['chunk_id']
            if chunk_id in combined_results:
                combined_results[chunk_id]['keyword_score'] = result['score']
                combined_results[chunk_id]['final_score'] += result['score'] * keyword_weight
            else:
                combined_results[chunk_id] = {
                    'chunk_id': chunk_id,
                    'content': result['content'],
                    'metadata': result['metadata'],
                    'semantic_score': 0,
                    'keyword_score': result['score'],
                    'final_score': result['score'] * keyword_weight
                }
        
        # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
        final_results = list(combined_results.values())
        final_results.sort(key=lambda x: x['final_score'], reverse=True)
        
        return final_results[:n_results]
    
    def quality_filtered_search(self, query: str, n_results: int = 5, 
                              min_quality_score: float = 0.5) -> List[Dict[str, Any]]:
        """í’ˆì§ˆ ì ìˆ˜ í•„í„°ë§ì´ ì ìš©ëœ ê²€ìƒ‰"""
        results = self.hybrid_search(query, n_results * 3)
        
        # í’ˆì§ˆ ì ìˆ˜ë¡œ í•„í„°ë§
        filtered_results = []
        for result in results:
            quality_score = result['metadata'].get('quality_score', 0)
            if quality_score >= min_quality_score:
                filtered_results.append(result)
                if len(filtered_results) >= n_results:
                    break
        
        return filtered_results
    
    def search_by_priority(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ìš°ì„ ìˆœìœ„ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰"""
        # ëª¨ë“  ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        all_results = self.hybrid_search(query, n_results * 5)
        
        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ê·¸ë£¹í™”
        high_priority = []
        medium_priority = []
        low_priority = []
        
        for result in all_results:
            priority = result['metadata'].get('search_priority', 'low')
            if priority == 'high':
                high_priority.append(result)
            elif priority == 'medium':
                medium_priority.append(result)
            else:
                low_priority.append(result)
        
        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ê²°ê³¼ êµ¬ì„±
        final_results = []
        high_count = min(len(high_priority), n_results // 2)
        medium_count = min(len(medium_priority), (n_results - high_count) // 2)
        low_count = n_results - high_count - medium_count
        
        final_results.extend(high_priority[:high_count])
        final_results.extend(medium_priority[:medium_count])
        final_results.extend(low_priority[:low_count])
        
        return final_results
    
    def get_chunk_by_id(self, chunk_id: str) -> Optional[Dict[str, Any]]:
        """ì²­í¬ IDë¡œ íŠ¹ì • ì²­í¬ ì¡°íšŒ"""
        try:
            result = self.collection.get(ids=[chunk_id])
            if result['ids']:
                return {
                    'chunk_id': result['ids'][0],
                    'content': result['documents'][0],
                    'metadata': result['metadatas'][0] if result['metadatas'] else {}
                }
        except:
            pass
        return None
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            count = self.collection.count()
            
            # í’ˆì§ˆ ì ìˆ˜ í†µê³„
            all_metadata = self.collection.get()['metadatas']
            quality_scores = [meta.get('quality_score', 0) for meta in all_metadata if meta]
            
            stats = {
                'total_chunks': count,
                'avg_quality_score': sum(quality_scores) / len(quality_scores) if quality_scores else 0,
                'high_quality_chunks': len([s for s in quality_scores if s > 0.7]),
                'medium_quality_chunks': len([s for s in quality_scores if 0.4 <= s <= 0.7]),
                'low_quality_chunks': len([s for s in quality_scores if s < 0.4])
            }
            
            return stats
        except Exception as e:
            return {'error': str(e)}
    
    def clear_collection(self):
        """ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„° ì‚­ì œ"""
        try:
            self.client.delete_collection(self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "Document chunks for RAG system"}
            )
            print(f"[âœ“] ì»¬ë ‰ì…˜ '{self.collection_name}'ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"[âŒ] ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    retriever = EnhancedRetriever()
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    query = "ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ìžë™í™”"
    print(f"[ðŸ”] ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    
    # ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²• í…ŒìŠ¤íŠ¸
    print("\n1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰:")
    results = retriever.hybrid_search(query, 3)
    for i, result in enumerate(results, 1):
        print(f"  {i}. {result['chunk_id']} (ì ìˆ˜: {result['final_score']:.3f})")
    
    print("\n2. í’ˆì§ˆ í•„í„°ë§ ê²€ìƒ‰:")
    results = retriever.quality_filtered_search(query, 3, min_quality_score=0.6)
    for i, result in enumerate(results, 1):
        print(f"  {i}. {result['chunk_id']} (í’ˆì§ˆ: {result['metadata'].get('quality_score', 0):.2f})")
    
    print("\n3. ìš°ì„ ìˆœìœ„ ê²€ìƒ‰:")
    results = retriever.search_by_priority(query, 3)
    for i, result in enumerate(results, 1):
        priority = result['metadata'].get('search_priority', 'low')
        print(f"  {i}. {result['chunk_id']} (ìš°ì„ ìˆœìœ„: {priority})")
    
    # í†µê³„ ì •ë³´
    stats = retriever.get_collection_stats()
    print(f"\nðŸ“Š ì»¬ë ‰ì…˜ í†µê³„: {stats}")
