# ì²­í‚¹ ë°©ì‹ë³„ ì‹¤í—˜ ë° ì„±ëŠ¥ ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
"""
4ê°€ì§€ ì²­í‚¹ ë°©ì‹(page, block, section, adaptive)ì„ ê°ê° í…ŒìŠ¤íŠ¸í•˜ê³ 
RAG ê²€ìƒ‰ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸

ì‹¤í—˜ ê³¼ì •:
1. ê° ì²­í‚¹ ë°©ì‹ìœ¼ë¡œ PDF ì²­í¬ ìƒì„±
2. ChromaDBì— ì¸ë±ì‹±
3. ë™ì¼í•œ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
4. ê²°ê³¼ ë¹„êµ ë° ë¶„ì„
"""

import sys
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Literal

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from scripts.parse_pdf import parse_pdf_to_chunks, compare_chunking_methods
from rag.retriever import EnhancedRetriever


class ChunkingExperiment:
    """ì²­í‚¹ ë°©ì‹ë³„ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, pdf_path: str, output_dir: str = "data/processed"):
        self.pdf_path = pdf_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.methods: List[Literal["page", "block", "section", "adaptive"]] = ["page", "block", "section", "adaptive"]
        self.results = {}
        
    def generate_chunks_for_all_methods(self):
        """ëª¨ë“  ì²­í‚¹ ë°©ì‹ìœ¼ë¡œ ì²­í¬ íŒŒì¼ ìƒì„±"""
        print("ğŸ”¬ ì²­í‚¹ ë°©ì‹ë³„ ì²­í¬ ìƒì„± ì‹œì‘")
        print("=" * 60)
        
        for method in self.methods:
            print(f"\nğŸ“‹ {method.upper()} ë°©ì‹ ì²˜ë¦¬ ì¤‘...")
            output_path = self.output_dir / f"pdf_chunks_{method}.json"
            
            try:
                chunks = parse_pdf_to_chunks(
                    pdf_path=self.pdf_path,
                    output_path=str(output_path),
                    document_id=f"smart_yard_intro_{method}",
                    chunking_method=method
                )
                
                self.results[method] = {
                    "chunk_count": len(chunks),
                    "avg_length": sum(len(chunk.get("content", "")) for chunk in chunks) // len(chunks) if chunks else 0,
                    "file_path": str(output_path),
                    "chunks": chunks
                }
                print(f"  âœ“ {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
                
            except Exception as e:
                print(f"  âŒ {method} ë°©ì‹ ì‹¤íŒ¨: {e}")
                self.results[method] = {"error": str(e)}
    
    def test_rag_performance(self, test_queries: List[str]):
        """ê° ì²­í‚¹ ë°©ì‹ë³„ RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ” RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ({len(test_queries)}ê°œ ì¿¼ë¦¬)")
        print("=" * 60)
        
        for method in self.methods:
            if "error" in self.results[method]:
                print(f"\nâŒ {method.upper()}: ì‹¤íŒ¨ - {self.results[method]['error']}")
                continue
                
            print(f"\nğŸ“Š {method.upper()} ë°©ì‹ RAG í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            try:
                # ChromaDB ì´ˆê¸°í™” ë° ì¸ë±ì‹±
                retriever = EnhancedRetriever()
                retriever.clear_collection()
                
                chunks = self.results[method]["chunks"]
                retriever.add_chunks(chunks)
                
                # ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
                search_results = {}
                total_time = 0
                
                for query in test_queries:
                    start_time = time.time()
                    results = retriever.hybrid_search(query, n_results=3)
                    end_time = time.time()
                    
                    search_time = end_time - start_time
                    total_time += search_time
                    
                    # ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€
                    avg_score = sum(result.get('final_score', 0) for result in results) / len(results) if results else 0
                    content_diversity = len(set(result.get('chunk_type', '') for result in results))
                    
                    search_results[query] = {
                        "results_count": len(results),
                        "avg_score": avg_score,
                        "search_time": search_time,
                        "content_diversity": content_diversity,
                        "top_result": results[0] if results else None
                    }
                
                # ì„±ëŠ¥ ì§€í‘œ ì €ì¥
                self.results[method]["rag_performance"] = {
                    "avg_search_time": total_time / len(test_queries),
                    "total_search_time": total_time,
                    "search_results": search_results,
                    "avg_score": sum(sr["avg_score"] for sr in search_results.values()) / len(search_results),
                    "avg_diversity": sum(sr["content_diversity"] for sr in search_results.values()) / len(search_results)
                }
                
                print(f"  âœ“ í‰ê·  ê²€ìƒ‰ ì‹œê°„: {self.results[method]['rag_performance']['avg_search_time']:.3f}ì´ˆ")
                print(f"  âœ“ í‰ê·  ì ìˆ˜: {self.results[method]['rag_performance']['avg_score']:.3f}")
                print(f"  âœ“ í‰ê·  ë‹¤ì–‘ì„±: {self.results[method]['rag_performance']['avg_diversity']:.1f}")
                
            except Exception as e:
                print(f"  âŒ RAG í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                self.results[method]["rag_performance"] = {"error": str(e)}
    
    def generate_comparison_report(self):
        """ì‹¤í—˜ ê²°ê³¼ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"\nğŸ“ˆ ì‹¤í—˜ ê²°ê³¼ ë¹„êµ ë¦¬í¬íŠ¸")
        print("=" * 60)
        
        # ë°ì´í„° ì¤€ë¹„
        report_data = []
        for method in self.methods:
            if "error" in self.results[method]:
                continue
                
            data = {
                "ë°©ì‹": method.upper(),
                "ì²­í¬ ìˆ˜": self.results[method]["chunk_count"],
                "í‰ê·  ì²­í¬ ê¸¸ì´": self.results[method]["avg_length"],
                "í‰ê·  ê²€ìƒ‰ ì‹œê°„(ì´ˆ)": self.results[method]["rag_performance"]["avg_search_time"],
                "í‰ê·  ì ìˆ˜": self.results[method]["rag_performance"]["avg_score"],
                "í‰ê·  ë‹¤ì–‘ì„±": self.results[method]["rag_performance"]["avg_diversity"]
            }
            report_data.append(data)
        
        # í‘œ í˜•íƒœë¡œ ì¶œë ¥
        print("\nğŸ“Š ì²­í‚¹ ë°©ì‹ë³„ ì„±ëŠ¥ ë¹„êµ:")
        print("-" * 80)
        print(f"{'ë°©ì‹':<12} {'ì²­í¬ ìˆ˜':<8} {'í‰ê·  ê¸¸ì´':<10} {'ê²€ìƒ‰ ì‹œê°„':<12} {'í‰ê·  ì ìˆ˜':<10} {'ë‹¤ì–‘ì„±':<8}")
        print("-" * 80)
        
        for data in report_data:
            print(f"{data['ë°©ì‹']:<12} {data['ì²­í¬ ìˆ˜']:<8} {data['í‰ê·  ì²­í¬ ê¸¸ì´']:<10} "
                  f"{data['í‰ê·  ê²€ìƒ‰ ì‹œê°„(ì´ˆ)']:<12.3f} {data['í‰ê·  ì ìˆ˜']:<10.3f} {data['í‰ê·  ë‹¤ì–‘ì„±']:<8.1f}")
        
        # ìµœê³  ì„±ëŠ¥ ë°©ì‹ ì°¾ê¸°
        if report_data:
            best_score = max(report_data, key=lambda x: x['í‰ê·  ì ìˆ˜'])
            best_speed = min(report_data, key=lambda x: x['í‰ê·  ê²€ìƒ‰ ì‹œê°„(ì´ˆ)'])
            best_diversity = max(report_data, key=lambda x: x['í‰ê·  ë‹¤ì–‘ì„±'])
            
            print(f"\nğŸ† ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼:")
            print(f"  â€¢ ìµœê³  ì ìˆ˜: {best_score['ë°©ì‹']} ({best_score['í‰ê·  ì ìˆ˜']:.3f})")
            print(f"  â€¢ ìµœê³  ì†ë„: {best_speed['ë°©ì‹']} ({best_speed['í‰ê·  ê²€ìƒ‰ ì‹œê°„(ì´ˆ)']:.3f}ì´ˆ)")
            print(f"  â€¢ ìµœê³  ë‹¤ì–‘ì„±: {best_diversity['ë°©ì‹']} ({best_diversity['í‰ê·  ë‹¤ì–‘ì„±']:.1f})")
        
        # ìƒì„¸ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        report_path = self.output_dir / "chunking_experiment_results.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {report_path}")
        
        return report_data
    
    def run_full_experiment(self):
        """ì „ì²´ ì‹¤í—˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        print("ğŸš€ ì²­í‚¹ ë°©ì‹ ì‹¤í—˜ ì‹œì‘")
        print("=" * 60)
        
        # 1. ì²­í¬ ìƒì„±
        self.generate_chunks_for_all_methods()
        
        # 2. RAG ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        test_queries = [
            "ìŠ¤ë§ˆíŠ¸ ì•¼ë“œë€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì¡°ì„  ì‚°ì—…ì˜ ë„ì „ ê³¼ì œëŠ”?",
            "AI ê¸°ìˆ ì˜ í™œìš© ë°©ì•ˆì€?",
            "ìƒì‚°ì„± í–¥ìƒ ë°©ë²•ì€?",
            "ìë™í™” ì‹œìŠ¤í…œì˜ íš¨ê³¼ëŠ”?"
        ]
        self.test_rag_performance(test_queries)
        
        # 3. ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        report_data = self.generate_comparison_report()
        
        print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")
        print("=" * 60)
        
        return report_data


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    pdf_file = "./data/raw/DR_ìŠ¤ë§ˆíŠ¸ì•¼ë“œê°œë¡ (ë°ëª¨ìš©).pdf"
    
    # ì‹¤í—˜ ì‹¤í–‰
    experiment = ChunkingExperiment(pdf_file)
    results_data = experiment.run_full_experiment()
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“‹ ì‹¤í—˜ ìš”ì•½:")
    print(f"  â€¢ í…ŒìŠ¤íŠ¸ëœ ì²­í‚¹ ë°©ì‹: {len(experiment.methods)}ê°œ")
    print(f"  â€¢ ìƒì„±ëœ ì²­í¬ íŒŒì¼: {len([m for m in experiment.methods if 'error' not in experiment.results[m]])}ê°œ")
    print(f"  â€¢ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: 5ê°œ")
    print(f"  â€¢ ê²°ê³¼ íŒŒì¼: data/processed/chunking_experiment_results.json")


if __name__ == "__main__":
    main() 