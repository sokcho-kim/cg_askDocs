# ê³µì •íšŒì˜ë¡ Excel íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
# ë‹´ë‹¹: ì œë¡œ
"""
Excel íŒŒì¼ì„ íŒë‹¤ìŠ¤ë¡œ ì½ì–´ í–‰/ì‹œíŠ¸ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
ê° ì²­í¬ëŠ” í†µì¼ëœ get_chunks() í¬ë§·ì— ë§ì¶° dictë¡œ ì €ì¥í•©ë‹ˆë‹¤.
ì˜ˆì‹œ:
{
    "chunk_id": "excel_doc_table_0",
    "document_id": "excel_doc",
    "chunk_index": 0,
    "chunk_type": "table",
    "location": "sheet:Sheet1,row:0",
    "content": "ì£¼ì°¨: 2452 | ëŒ€ë¶„ë¥˜: ì‚¬ì™¸ | íŒ€: ì‚¬ì™¸ê³µì •ê´€ë¦¬íŒ€ | ì´ìŠˆ: ì‚¬ì™¸ë¸”ë¡ 2ê°œ ì…ê³  ì§€ì—°",
    "embedding": null,
    "metadata": {
        "length": 45,
        "chunk_in_content": 0,
        "row_index": 0,
        "sheet_name": "Sheet1",
        "columns": ["ì£¼ì°¨", "ëŒ€ë¶„ë¥˜", "íŒ€", "ì´ìŠˆ"],
        "data_type": "excel_row"
    }
}
"""

import pandas as pd
import json
import uuid
from pathlib import Path
from typing import List, Dict, Any, Optional
from utils.chunk_processor import ExcelChunkProcessor


def parse_excel_file(filepath: str, output_path: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    Excel íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ í†µì¼ëœ ì²­í¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        filepath: Excel íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
    
    Returns:
        ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    # íŒŒì¼ëª…ì—ì„œ document_id ìƒì„±
    filename = Path(filepath).stem
    document_id = f"excel_{filename}"
    
    # Excel íŒŒì¼ ì½ê¸°
    excel_file = pd.ExcelFile(filepath)
    
    # ì²­í¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = ExcelChunkProcessor(document_id=document_id)
    
    all_chunks = []
    
    # ê° ì‹œíŠ¸ë³„ë¡œ ì²˜ë¦¬
    for sheet_name in excel_file.sheet_names:
        print(f"[ğŸ“Š] ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘: {sheet_name}")
        
        # ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
        df = pd.read_excel(filepath, sheet_name=sheet_name)
        
        # ë¹ˆ í–‰ ì œê±°
        df = df.dropna(how='all')
        
        # ë°ì´í„°í”„ë ˆì„ì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        df_data = df.to_dict('records')
        
        # ì²­í¬ ìƒì„±
        chunks = processor.process_excel_data(df_data, sheet_name)
        all_chunks.extend(chunks)
        
        print(f"[âœ“] {sheet_name}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if output_path is None:
        output_path = f"data/processed/{filename}_chunks.json"
    
    # ì²­í¬ ì €ì¥
    processor.chunks = all_chunks
    processor.save_chunks(output_path)
    
    print(f"[ğŸ‰] ì´ {len(all_chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
    return all_chunks


def convert_existing_excel_metadata(input_path: str, output_path: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    ê¸°ì¡´ excel_metadata.jsonì„ í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        input_path: ê¸°ì¡´ excel_metadata.json ê²½ë¡œ
        output_path: ë³€í™˜ëœ íŒŒì¼ ì €ì¥ ê²½ë¡œ
    
    Returns:
        ë³€í™˜ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
    with open(input_path, 'r', encoding='utf-8') as f:
        old_chunks = json.load(f)
    
    # í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    converted_chunks = []
    chunk_index = 0
    
    for old_chunk in old_chunks:
        # ê¸°ì¡´ í˜•ì‹ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
        row_index = old_chunk.get('row_index', 0)
        column = old_chunk.get('column', '')
        content = old_chunk.get('content', '')
        
        # í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        new_chunk = {
            "chunk_id": f"excel_converted_{chunk_index}",
            "document_id": "excel_converted",
            "chunk_index": chunk_index,
            "chunk_type": "table",
            "location": f"row:{row_index}",
            "content": content,
            "embedding": None,
            "metadata": {
                "length": len(content),
                "chunk_in_content": 0,
                "row_index": row_index,
                "column": column,
                "data_type": "excel_row_converted"
            }
        }
        
        converted_chunks.append(new_chunk)
        chunk_index += 1
    
    # ë³€í™˜ëœ ë°ì´í„° ì €ì¥
    if output_path is None:
        output_path = input_path.replace('.json', '_converted.json')
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(converted_chunks, f, ensure_ascii=False, indent=2)
    
    print(f"[ğŸ”„] {len(converted_chunks)}ê°œ ì²­í¬ ë³€í™˜ ì™„ë£Œ -> {output_path}")
    return converted_chunks


if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    excel_file = "data/raw/DR_ê³µì •íšŒì˜ìë£Œ_ì¶”ì¶œë³¸(ë°ëª¨ìš©).xlsx"
    
    if Path(excel_file).exists():
        print(f"[ğŸš€] Excel íŒŒì¼ íŒŒì‹± ì‹œì‘: {excel_file}")
        chunks = parse_excel_file(excel_file)
        print(f"[âœ…] íŒŒì‹± ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
    else:
        print(f"[âŒ] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file}")
        
        # ê¸°ì¡´ excel_metadata.json ë³€í™˜
        existing_file = "data/processed/excel_metadata.json"
        if Path(existing_file).exists():
            print(f"[ğŸ”„] ê¸°ì¡´ íŒŒì¼ ë³€í™˜ ì‹œì‘: {existing_file}")
            convert_existing_excel_metadata(existing_file)
        else:
            print(f"[âŒ] ë³€í™˜í•  íŒŒì¼ë„ ì—†ìŠµë‹ˆë‹¤: {existing_file}")
